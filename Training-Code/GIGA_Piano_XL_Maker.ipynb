{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "ac5a4cf0-d9d2-47b5-9633-b53f8d99a4d2",
          "kernelId": ""
        },
        "id": "SiTIpPjArIyr"
      },
      "source": [
        "# GIGA-Piano XL Maker (ver. 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2022\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "fa0a611c-1803-42ae-bdf6-a49b5a4e781b",
          "kernelId": ""
        },
        "id": "gOd93yV0sGd2"
      },
      "source": [
        "# (Setup Environment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "39411b40-9e39-416e-8fe4-d40f733e7956",
          "kernelId": ""
        },
        "id": "lw-4aqV3sKQG"
      },
      "outputs": [],
      "source": [
        "#@title nvidia-smi gpu check\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "a1a45a91-d909-4fd4-b67a-5e16b971d179",
          "kernelId": ""
        },
        "id": "fX12Yquyuihc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "\n",
        "!git clone https://github.com/asigalov61/GIGA-Piano-XL\n",
        "\n",
        "!pip install torch\n",
        "\n",
        "!pip install pickle5\n",
        "\n",
        "!pip install tqdm\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "b8207b76-9514-4c07-95db-95a4742e52c5",
          "kernelId": ""
        },
        "id": "z7n9vnKmug1J"
      },
      "outputs": [],
      "source": [
        "#@title Import all needed modules\n",
        "\n",
        "print('Loading needed modules. Please wait...')\n",
        "import os\n",
        "import random\n",
        "import secrets\n",
        "from collections import OrderedDict\n",
        "import pickle5\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "print('Loading core modules...')\n",
        "os.chdir('/content/GIGA-Piano-XL')\n",
        "\n",
        "import TMIDIX\n",
        "from GPT2RGAX import *\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "20b8698a-0b4e-4fdb-ae49-24d063782e77",
          "kernelId": ""
        },
        "id": "ObPxlEutsQBj"
      },
      "source": [
        "# (TRAIN FROM SCRATCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Sample Piano Datasets"
      ],
      "metadata": {
        "id": "CuoSVD2fjvWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ALL-Piano Dataset\n",
        "%cd /content/Dataset/\n",
        "!wget --no-check-certificate -O 'ALL-Piano.zip' \"https://onedrive.live.com/download?cid=8A0D502FC99C608F&resid=8A0D502FC99C608F%2118569&authkey=AAYVqXUlxXmpFqk\"\n",
        "!unzip ALL-Piano.zip\n",
        "!rm ALL-Piano.zip\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "z5E8HXOJX-xZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GiantMIDI Dataset\n",
        "%cd /content/Dataset/\n",
        "!wget --no-check-certificate -O 'GiantMIDI.zip' \"https://onedrive.live.com/download?cid=8A0D502FC99C608F&resid=8A0D502FC99C608F%2118494&authkey=AJr3wBuauBiEzVQ\"\n",
        "!unzip GiantMIDI.zip\n",
        "!rm GiantMIDI.zip\n",
        "%cd /content/"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VdTW_pjp5QuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MAESTRO Dataset\n",
        "%cd /content/Dataset/\n",
        "!wget https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip\n",
        "!unzip maestro-v3.0.0-midi.zip\n",
        "!rm maestro-v3.0.0-midi.zip\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "72h2AzVQ5hph",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (PROCESS MIDIs)"
      ],
      "metadata": {
        "id": "PDef3vLcgeYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process MIDIs with TMIDIX MIDI Processor\n",
        "\n",
        "#@title Process MIDIs\n",
        "\n",
        "sorted_or_random_file_loading_order = False # Sorted order is NOT usually recommended\n",
        "dataset_ratio = 1 # Change this if you need more data\n",
        "\n",
        "\n",
        "print('TMIDIX MIDI Processor')\n",
        "print('Starting up...')\n",
        "###########\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "gfiles = []\n",
        "\n",
        "train_data1 = []\n",
        "\n",
        "###########\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"/content/Dataset\"\n",
        "# os.chdir(dataset_addr)\n",
        "filez = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "if filez == []:\n",
        "    print('Could not find any MIDI files. Please check Dataset dir...')\n",
        "    print('=' * 70)\n",
        "\n",
        "if sorted_or_random_file_loading_order:\n",
        "    print('Sorting files...')\n",
        "    filez.sort()\n",
        "    print('Done!')\n",
        "    print('=' * 70)\n",
        "else:\n",
        "    print('Randomizing file list...')\n",
        "    random.shuffle(filez)\n",
        "\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm(filez[:int(len(filez) * dataset_ratio)]):\n",
        "    try:\n",
        "        fn = os.path.basename(f)\n",
        "        fn1 = fn.split('.')[0]\n",
        "\n",
        "        #print('Loading MIDI file...')\n",
        "        score = TMIDIX.midi2ms_score(open(f, 'rb').read())\n",
        "\n",
        "        events_matrix = []\n",
        "\n",
        "        itrack = 1\n",
        "\n",
        "        while itrack < len(score):\n",
        "            for event in score[itrack]:         \n",
        "                if event[0] == 'note' and event[3] != 9:\n",
        "                    events_matrix.append(event)\n",
        "            itrack += 1\n",
        "        \n",
        "        if len(events_matrix) > 0:\n",
        "\n",
        "          # Sorting...\n",
        "          events_matrix.sort(key=lambda x: x[4], reverse=True)\n",
        "          events_matrix.sort(key=lambda x: x[1])\n",
        "\n",
        "          # recalculating timings\n",
        "          for e in events_matrix:\n",
        "              e[1] = int(e[1] / 10)\n",
        "              e[2] = int(e[2] / 20)\n",
        "          \n",
        "          # final processing...\n",
        "\n",
        "          train_data1.extend([126+0, 126+128, 0+256, 0+384]) # Intro/Zero seq\n",
        "\n",
        "          pe = events_matrix[0]\n",
        "          for e in events_matrix:\n",
        "\n",
        "              time = max(0, min(126, e[1]-pe[1]))\n",
        "              dur = max(1, min(126, e[2]))\n",
        "              ptc = max(1, min(126, e[4]))\n",
        "              vel = max(1, min(126, e[5]))\n",
        "\n",
        "              train_data1.extend([time+0, dur+128, ptc+256, vel+384])\n",
        "\n",
        "              pe = e\n",
        "\n",
        "          files_count += 1\n",
        "        \n",
        "    except KeyboardInterrupt:\n",
        "        print('Quitting...')\n",
        "        break  \n",
        "\n",
        "    except:\n",
        "        print('Bad MIDI:', f)\n",
        "        continue\n",
        "\n",
        "print('=' * 70)\n",
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(train_data1, '/content/GIGA_Piano_XL_Processed_MIDIs')        \n",
        "print('Done!')   \n",
        "print('=' * 70)"
      ],
      "metadata": {
        "id": "HBrR4lz9HwTa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (TRAIN FROM PROVIDED TRAINING DATA)"
      ],
      "metadata": {
        "id": "yvl1nONbQXGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download GIGA-Piano XL Training Data\n",
        "\n",
        "%cd /content/\n",
        "!wget --no-check-certificate -O 'GIGA-Piano-XL-Perceiver-Training-Data.zip' \"https://onedrive.live.com/download?cid=8A0D502FC99C608F&resid=8A0D502FC99C608F%2118740&authkey=ANEK-9WanNFyalw\"\n",
        "!unzip 'GIGA-Piano-XL-Perceiver-Training-Data.zip'\n",
        "!rm 'GIGA-Piano-XL-Perceiver-Training-Data.zip'\n",
        "%cd /content/"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7ivhGCBpi-nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load training data\n",
        "\n",
        "#@markdown NOTE: You will need at least 64GB RAM to load the training data\n",
        "\n",
        "#@markdown NOTE: This training data pack uses Pickle Protocol 5 so install pickle5 to load\n",
        "\n",
        "train_data1 = pickle5.load(open('/content/GP-Perceiver-Training-Data.pickle', 'rb'))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QXl6qem2kB0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (TEST INTs)"
      ],
      "metadata": {
        "id": "BdKs7Gy2zAqf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "execution_count": 6,
          "id": "dd411e56-532f-47dd-8283-ecb57126a3ae",
          "kernelId": ""
        },
        "id": "p14gn48SHX90",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Test resulting INTs\n",
        "\n",
        "idx = random.randint(0, len(train_data1) // 2048)\n",
        "\n",
        "out1 = train_data1[2048*idx:2048*(idx+1)]\n",
        "\n",
        "print('=' * 70)\n",
        "print('Sample INTs', out1[:15])\n",
        "print('=' * 70)\n",
        "\n",
        "if len(out1) != 0:\n",
        "    \n",
        "    song = out1\n",
        "    song_f = []\n",
        "    time = 0\n",
        "    dur = 0\n",
        "    vel = 0\n",
        "    pitch = 0\n",
        "    channel = 0\n",
        "\n",
        "    son = []\n",
        "\n",
        "    song1 = []\n",
        "\n",
        "    for s in song:\n",
        "      if s > 127:\n",
        "        son.append(s)\n",
        "\n",
        "      else:\n",
        "        if len(son) == 4:\n",
        "          song1.append(son)\n",
        "        son = []\n",
        "        son.append(s)\n",
        "    \n",
        "    for s in song1:\n",
        "\n",
        "        channel = 0 # Piano\n",
        "\n",
        "        time += s[0] * 10\n",
        "            \n",
        "        dur = (s[1]-128) * 20\n",
        "        \n",
        "        pitch = (s[2]-256)\n",
        "\n",
        "        vel = (s[3]-384)\n",
        "                                  \n",
        "        song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "\n",
        "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
        "                                                        output_signature = 'GIGA-Piano XL',  \n",
        "                                                        output_file_name = '/content/GIGA-Piano-XL-Music-Composition', \n",
        "                                                        track_name='Project Los Angeles',\n",
        "                                                        list_of_MIDI_patches=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                                                        number_of_ticks_per_quarter=500)\n",
        "\n",
        "    print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkVqviDzJOrv"
      },
      "source": [
        "# (TRAIN)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load processed INTs dataset\n",
        "\n",
        "SEQ_LEN = max_seq\n",
        "\n",
        "BATCH_SIZE = 1 # Change this to your specs (4 batches per 48GB)\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "print('=' * 50)\n",
        "print('Loading training data...')\n",
        "\n",
        "data_train, data_val = torch.Tensor(train_data1), torch.Tensor(train_data1[:8192])\n",
        "\n",
        "class MusicSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        rand = secrets.randbelow((self.data.size(0)-(self.seq_len)) // (self.seq_len)) * (self.seq_len)\n",
        "\n",
        "        x = self.data[rand: rand + self.seq_len].long()\n",
        "        trg = self.data[(rand+1): (rand+1) + self.seq_len].long()\n",
        "        \n",
        "        return x, trg\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) # // self.seq_len if you want exact training time per epoch\n",
        "\n",
        "train_dataset = MusicSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = MusicSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
        "val_loader    = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
        "\n",
        "print('=' * 50)\n",
        "print('Total INTs in the dataset', len(train_data1))\n",
        "print('Length of the dataset:',len(train_dataset))\n",
        "print('Number of batched samples per epoch:', len(train_data1) // max_seq // BATCH_SIZE)\n",
        "print('=' * 50)\n",
        "print('Sample train dataset:', train_dataset[0])\n",
        "print('Sample val dataset:', val_dataset[0])\n",
        "print('=' * 50)\n",
        "print('Train loader length:', len(train_loader))\n",
        "print('Val loader length:', len(val_loader))\n",
        "print('=' * 50)\n",
        "print('Done! Enjoy! :)')\n",
        "print('=' * 50)"
      ],
      "metadata": {
        "id": "_KoJ-hwP5iU2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "4aa21407-a3e9-4ed2-9bf1-83c295482b8a",
          "kernelId": ""
        },
        "id": "2moo7uUmpxvC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Train the model\n",
        "\n",
        "print('Setting-up model...Please wait...')\n",
        "\n",
        "DIC_SIZE = 512\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "config = GPTConfig(DIC_SIZE, \n",
        "                   max_seq,\n",
        "                   dim_feedforward=2048,\n",
        "                   n_layer=24, \n",
        "                   n_head=8, \n",
        "                   n_embd=1024,\n",
        "                   enable_rpr=True,\n",
        "                   er_len=max_seq)\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = GPT(config)\n",
        "\n",
        "model = nn.DataParallel(model) # Multi-GPU training...\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "print('Done!')\n",
        "\n",
        "#===\n",
        "\n",
        "best_eval_acc        = 0.0\n",
        "best_eval_acc_epoch  = -1\n",
        "best_eval_loss       = float(\"inf\")\n",
        "best_eval_loss_epoch = -1\n",
        "best_acc_file = '/content/gpt2_rpr_acc.pth'\n",
        "best_loss_file = '/content/gpt2_rpr_loss.pth'\n",
        "loss_train, loss_val, acc_val = [], [], []\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    new_best = False\n",
        "    \n",
        "    loss = train(epoch+1, \n",
        "                 model, train_loader, \n",
        "                 train_loss_func, \n",
        "                 opt, \n",
        "                 lr_scheduler, \n",
        "                 num_iters=-1, \n",
        "                 save_checkpoint_steps=4000)\n",
        "    \n",
        "    loss_train.append(loss)\n",
        "    \n",
        "    eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)\n",
        "    loss_val.append(eval_loss)\n",
        "    acc_val.append(eval_acc)\n",
        "    \n",
        "    if(eval_acc > best_eval_acc):\n",
        "        best_eval_acc = eval_acc\n",
        "        best_eval_acc_epoch  = epoch+1\n",
        "        torch.save(model.state_dict(), best_acc_file)\n",
        "        new_best = True\n",
        "\n",
        "    if(eval_loss < best_eval_loss):\n",
        "        best_eval_loss       = eval_loss\n",
        "        best_eval_loss_epoch = epoch+1\n",
        "        torch.save(model.state_dict(), best_loss_file)\n",
        "        new_best = True\n",
        "    \n",
        "    if(new_best):\n",
        "        print(\"Best eval acc epoch:\", best_eval_acc_epoch)\n",
        "        print(\"Best eval acc:\", best_eval_acc)\n",
        "        print(\"\")\n",
        "        print(\"Best eval loss epoch:\", best_eval_loss_epoch)\n",
        "        print(\"Best eval loss:\", best_eval_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "72338f3f-34c4-40e3-a48a-42ed9729466a",
          "kernelId": ""
        },
        "id": "R4LIXk1vHX92",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Eval funct to eval separately if needed\n",
        "\n",
        "DIC_SIZE = 512\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "\n",
        "eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdKFoeke9L7H"
      },
      "source": [
        "# (MODEL SAVE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "id": "73bea62d-084b-4f9a-9e55-2b34a932a7a4",
          "kernelId": ""
        },
        "id": "gqyDatHC9X1z"
      },
      "outputs": [],
      "source": [
        "#@title Save the model\n",
        "\n",
        "print('Saving the model...')\n",
        "full_path_to_model_checkpoint = \"/content/GIGA-Piano-XL-Trained-Model.pth\" #@param {type:\"string\"}\n",
        "torch.save(model.state_dict(), full_path_to_model_checkpoint)\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzCMd94Tu_gz"
      },
      "source": [
        "# Congrats! You did it! :)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
